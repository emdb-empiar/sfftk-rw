# -*- coding: utf-8 -*-
from __future__ import division, print_function

"""
========================
sfftkrw.schema.adapter
========================

This module defines an usable adapter API to the one generated by
`generateDS <http://www.davekuhlman.org/generateDS.html>`_ API. It is designed to fulfill several requirements:

-   allow multiple versions of generateDS APIs to exist for the same adapter;

-   implement more convenient ways of working with the classes of the API;

-   easily integrate new EMDB-SFF entities into the API;

-   decouple the file format from the data model: most classes in this adapter implement methods to handle conversion
    to non-XML formats (XML is the only format that `generateDS <http://www.davekuhlman.org/generateDS.html>`_ writes
    to)

Here is an example of how the :py:class:`SFFSegmentation` class is defined using these classes:

.. code:: python

    class SFFSegmentation(SFFType):
        \"""Adapter class to make using the output of ``generateDS`` easier to use\"""
        gds_type = sff.segmentation
        ref = "Segmentation"
        repr_string = ""

        # attributes
        name = SFFAttribute('name')
        version = SFFAttribute('version')
        software = SFFAttribute('software', sff_type=SFFSoftware)
        primary_descriptor = SFFAttribute('primaryDescriptor')
        transforms = SFFAttribute('transformList', sff_type=SFFTransformList)
        bounding_box = SFFAttribute('boundingBox', sff_type=SFFBoundingBox)
        global_external_references = SFFAttribute('global_external_references', sff_type=SFFGlobalExternalReferences)
        segments = SFFAttribute('segmentList', sff_type=SFFSegmentList)
        details = SFFAttribute('details')

In the above example, the :py:class:`SFFSegmentation` class inherits from :py:class:`SFFType` which uses the first
three attributes (``gds_type``, ``ref`` and ``repr_string``) to configure the user-level :py:class:`SFFSegmentation`
class. A user can now use :py:class:`SFFSegmentation` normally:

.. code:: python

    from sfftkrw.schema import SFFSegmentation

    # to create a new empty EMDB-SFF segmentation object
    seg = SFFSegmentation()

    # to open an XML-, HDF5- or JSON-formatted file, respectively
    seg = SFFSegmentation('file.sff')
    seg = SFFSegmentation('file.hff')
    seg = SFFSegmentation('file.json')

The attributes (``name``, ``version``, etc.) are all instances of :py:class:`SFFAttribute`, which takes the name (first
positional argument) and an optional keyword argument ``sff_type`` denoting the class of the attribute. In the above
example, the ``software`` attribute will be of class :py:class:`SFFSoftware`.

"""

import base64
import numbers
import os
import random
import struct
import sys
import re
import zlib

import h5py
import numpy as np

from . import emdb_sff as sff
from .base import SFFType, SFFAttribute, SFFListType, SFFTypeError, SFFIndexType
from ..core import _basestring, _decode, _dict, _str, _encode, _bytes, _xrange
from ..core.print_tools import print_date

FORMAT_CHARS = {
    'int8': 'b',
    'uint8': 'B',
    'int16': 'h',
    'uint16': 'H',
    'int32': 'i',
    'uint32': 'I',
    'int64': 'q',
    'uint64': 'Q',
    'float32': 'f',
    'float64': 'd',
}

ENDIANNESS = {
    'little': '<',
    'big': '>',
}

# ensure that we can read/write encoded data
sff.ExternalEncoding = "utf-8"


class SFFRGBA(SFFType):
    """RGBA colour"""
    gds_type = sff.rgbaType
    ref = "RGBA colour"
    repr_string = "SFFRGBA(red={}, green={}, blue={}, alpha={})"
    repr_args = ('red', 'green', 'blue', 'alpha')

    # attributes
    red = SFFAttribute('red', help="red channel")
    green = SFFAttribute('green', help="green channel")
    blue = SFFAttribute('blue', help="blue channel")
    alpha = SFFAttribute('alpha', help="alpha (opacity) channel")

    def __init__(self, random_colour=False, *args, **kwargs):
        super(SFFRGBA, self).__init__(*args, **kwargs)
        if random_colour:
            self.value = random.random(), random.random(), random.random()

    @property
    def value(self):
        return self.red, self.green, self.blue, self.alpha

    @value.setter
    def value(self, c):
        if len(c) == 3:
            self.red, self.green, self.blue = c
        elif len(c) == 4:
            self.red, self.green, self.blue, self.alpha = c

    def __repr__(self):
        return str(self.value)

    def _boolean_test(self):
        if self.red is None or self.green is None or self.blue is None or self.alpha is None:
            return False
        else:
            return True

    if sys.version_info[0] > 2:
        def __bool__(self):
            return self._boolean_test()
    else:
        def __nonzero__(self):
            return self._boolean_test()

    def as_hff(self, parent_group, name="colour"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        parent_group[name] = self.value
        # group = parent_group.create_group(name)
        # group['rgba'] = self.value
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        # r = SFFRGBA()
        obj.value = hff_data['colour'][()]
        # obj.rgba = r
        return obj



class SFFComplexes(SFFListType, SFFType):
    """Class that encapsulates complex"""
    gds_type = sff.complexType
    ref = "Complexes"
    repr_string = "Complex list of length {}"
    repr_args = ('len()',)
    iter_attr = ('id', _str)

    id = SFFAttribute('id', help="the list of complex ids")

    def set_complexes(self, cs):
        """Set value to the iterable of complexes

        :param list cs: an iterable of complex accessions
        """
        if isinstance(cs, list):
            self._local.set_id(cs)
        else:
            raise SFFTypeError(cs, list)

    def add_complex(self, c):
        """Add a complex accession to the available complexes

        :param str c: a complex accession
        """
        if isinstance(c, _basestring):
            self._local.add_id(c)
        else:
            raise SFFTypeError(c, _basestring)

    def insert_complex_at(self, index, c):
        """Insert a complex accession at the given index

        :param int index: the index in the iterable of complexes at which to add the new complex accession
        :param str c: a complex accession
        """
        # todo: handle IndexError
        if isinstance(c, _basestring):
            self._local.insert_id_at(index, c)
        else:
            raise SFFTypeError(c, _basestring)

    def replace_complex_at(self, index, c):
        """Replace a complex accession at the given index

        :param int index: the index in the iterable of complexes at which to replace the complex accession
        :param str c: a complex accession
        """
        # todo: handle IndexError
        if isinstance(c, _basestring):
            self._local.replace_id_at(index, c)
        else:
            raise SFFTypeError(c, _basestring)

    def delete_complex_at(self, index):
        """Delete the complex accession at the given index

        :param int index: index from which to delete the complex accession
        """
        del self._local.id[index]

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Dataset)
        obj = cls()
        [obj.add_complex(_decode(_, 'utf-8')) for _ in hff_data]
        return obj


class SFFMacromolecules(SFFListType, SFFType):
    """Class that encapsulates macromolecule"""
    gds_type = sff.macromoleculeType
    ref = "Macromolecules"
    repr_string = "Macromolecule list of length {}"
    repr_args = ("len()",)
    # todo: same problem as SFFComplexes
    iter_attr = ('id', str)
    iter_dict = _dict()

    def set_macromolecules(self, ms):
        """Set the value of macromoleclues to the provided list of macromolecule accessions

        :param list ms: a list of macromolecule accessions
        """
        if isinstance(ms, list):
            self._local.set_id(ms)
        else:
            raise SFFTypeError(ms, list)

    def add_macromolecule(self, m):
        """Add the given macromolecule accession to this container

        :param str m: a macromolecule accession
        """
        if isinstance(m, _basestring):
            self._local.add_id(m)

        else:
            raise SFFTypeError(m, _basestring)

    def insert_macromolecule_at(self, index, m):
        """Insert the given macromolecule accession at the specified index bumping all others down the list

        :param int index: the index to insert at
        :param str m: a macromolecule accession
        """
        if isinstance(m, _basestring):
            self._local.insert_id_at(index, m)
        else:
            raise SFFTypeError(m, _basestring)

    def replace_macromolecule_at(self, index, m):
        """Replace the macromolecule accession at the specified index with the one specified

        :param int index: the index to insert at
        :param str m: a macromolecule accession
        """
        if isinstance(m, _basestring):
            self._local.replace_id_at(index, m)
        else:
            raise SFFTypeError(m, _basestring)

    def delete_at(self, index):
        """Delete the macromolecule accession at the give index

        :param int index: index of macromolecule accession to delete
        """
        del self._local.id[index]

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Dataset)
        obj = cls()
        [obj.add_macromolecule(_decode(_, 'utf-8')) for _ in hff_data]
        return obj


class SFFComplexesAndMacromolecules(SFFType):
    """Complexes and macromolecules"""
    gds_type = sff.macromoleculesAndComplexesType
    ref = "Complexes and macromolecules"
    repr_string = "Complexes: {}; Macromolecules: {}"
    repr_args = ('num_complexes', 'num_macromolecules')

    # attributes
    complexes = SFFAttribute('complex', sff_type=SFFComplexes, help="a list of complex accessions")
    macromolecules = SFFAttribute('macromolecule', sff_type=SFFMacromolecules,
                                  help="a list of macromolecule accessions")

    @property
    def num_complexes(self):
        return len(self.complexes)

    @property
    def num_macromolecules(self):
        return len(self.macromolecules)

    def _boolean_test(self):
        if self.complexes or self.macromolecules:
            return True
        else:
            return False

    if sys.version_info[0] > 2:
        def __bool__(self):
            return self._boolean_test()
    else:
        def __nonzero__(self):
            return self._boolean_test()

    def as_hff(self, parent_group, name="complexesAndMacromolecules"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        if self.complexes:
            group['complexes'] = self.complexes
        if self.macromolecules:
            group['macromolecules'] = self.macromolecules
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        if "complexes" in hff_data:
            obj.complexes = SFFComplexes.from_hff(hff_data['complexes'])
        if "macromolecules" in hff_data:
            obj.macromolecules = SFFMacromolecules.from_hff(hff_data['macromolecules'])
        return obj


class SFFExternalReference(SFFIndexType, SFFType):
    """Class that encapsulates an external reference"""
    gds_type = sff.externalReferenceType
    ref = "external_reference"
    repr_string = "Reference: {}; {}; {}"
    repr_args = ('type', 'other_type', 'value')
    ref_id = 0
    index_attr = 'ref_id'

    # attributes
    id = SFFAttribute('id', help="this external reference's ID")
    type = SFFAttribute('type_', help="the ontology/archive name")
    other_type = SFFAttribute('otherType', help="a URL/IRI where data for this external reference may be obtained")
    value = SFFAttribute('value', help="the accession for this external reference")
    label = SFFAttribute('label', help="a short description of this external reference")
    description = SFFAttribute('description', help="a long description of this external reference")

    # methods
    def __init__(self, *args, **kwargs):
        # remap kwargs
        if 'type' in kwargs:
            kwargs['type_'] = kwargs['type']
            del kwargs['type']
        super(SFFExternalReference, self).__init__(*args, **kwargs)


class SFFExternalReferences(SFFListType, SFFType):
    """Container for external references"""
    gds_type = sff.externalReferencesType
    ref = "external_references"
    repr_string = "External references list with {} reference(s)"
    repr_args = ('len()',)
    iter_attr = ('ref', SFFExternalReference)
    iter_dict = _dict()

    # methods
    def add_external_reference(self, e_r):
        """Add the specified external reference object to this container

        :param e_r: an external reference object
        :type e_r: :py:class:`SFFExternalReference`
        """
        if isinstance(e_r, SFFExternalReference):
            self._local.add_ref(e_r._local)
        else:
            raise SFFTypeError(e_r, SFFExternalReference)

    def insert_external_reference(self, e_r, index):
        """Insert the specified external reference object at the specified index

        :param e_r: an external reference object
        :type e_r: :py:class:`SFFExternalReference`
        :param int index: the index to insert to; bumps all other external references down the list
        """
        # todo: catch IndexError
        if isinstance(e_r, SFFExternalReference) and isinstance(index, int):
            self._local.insert_ref_at(index, e_r._local)
        else:
            if not isinstance(e_r, SFFExternalReference):
                raise SFFTypeError(e_r, SFFExternalReference)
            elif not isinstance(index, int):
                raise SFFTypeError(index, int)

    def replace_external_reference(self, e_r, index):
        """Replace the external reference at ``index`` with the specified external reference

        :param e_r: an external reference object
        :type e_r: :py:class:`SFFExternalReference`
        :param int index: the index to replace at
        """
        if isinstance(e_r, SFFExternalReference) and isinstance(index, int):
            self._local.replace_ref_at(index, e_r._local)
        else:
            if not isinstance(e_r, SFFExternalReference):
                raise SFFTypeError(e_r, SFFExternalReference)
            elif not isinstance(index, int):
                raise SFFTypeError(index, int)


class SFFBiologicalAnnotation(SFFType):
    """Biological annotation"""
    gds_type = sff.biologicalAnnotationType
    ref = "biological_annotation"
    repr_string = "Container for biological annotation with {} external references"
    repr_args = ('num_external_references',)

    # attributes
    name = SFFAttribute('name', help="the name of this segment")
    description = SFFAttribute('description', help="a brief description for this segment")
    external_references = SFFAttribute('externalReferences', sff_type=SFFExternalReferences,
                                       help="the set of external references")
    number_of_instances = SFFAttribute('numberOfInstances', help="the number of instances of this segment")

    # methods
    def _boolean_test(self):
        if not self.description and not self.external_references and not self.number_of_instances:
            return False
        else:
            return True

    if sys.version_info[0] > 2:
        def __bool__(self):
            return self._boolean_test()
    else:
        def __nonzero__(self):
            return self._boolean_test()

    @property
    def num_external_references(self):
        return len(self.external_references)

    def as_hff(self, parent_group, name="biologicalAnnotation"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        if self:
            vl_str = h5py.special_dtype(vlen=_str)
            h_ext = group.create_dataset(
                "externalReferences",
                (self.num_external_references,),
                dtype=[
                    ('type', vl_str),
                    ('otherType', vl_str),
                    ('value', vl_str),
                    ('label', vl_str),
                    ('description', vl_str),
                ]
            )
            # description and nubmerOfInstances as attributes
            group['name'] = self.name if self.name else ''
            group['description'] = self.description if self.description else ''
            if isinstance(self.number_of_instances, numbers.Integral):
                group['numberOfInstances'] = self.number_of_instances if self.number_of_instances > 0 else 0
            else:
                group['numberOfInstances'] = 0
            i = 0
            for extref in self.external_references:
                h_ext[i] = (extref.type, extref.other_type, extref.value, extref.label, extref.description)
                i += 1
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        if 'name' in hff_data:
            obj.name = _decode(hff_data['name'][()], 'utf-8')
        if 'description' in hff_data:
            obj.description = _decode(hff_data['description'][()], 'utf-8')
        obj._number_ofi = int(hff_data['numberOfInstances'][()])
        if "externalReferences" in hff_data:
            obj.external_references = SFFExternalReferences()
            for ref in hff_data['externalReferences']:
                e = SFFExternalReference()
                e.type, e.other_type, e.value, e.label, e.description = list(map(lambda r: _decode(r, 'utf-8'), ref))
                obj.external_references.add_external_reference(e)
        return obj


class SFFThreeDVolume(SFFType):
    """Class representing segments described using a 3D volume"""
    gds_type = sff.threeDVolumeType
    ref = 'three_d_volume'
    repr_string = "3D formatted segment"

    # attributes
    lattice_id = SFFAttribute('latticeId', help="the ID of the lattice that has the data for this 3D volume")
    value = SFFAttribute('value', help="the voxel values associated with this 3D volume")
    transform_id = SFFAttribute('transformId', help="a transform applied to this 3D volume [optional]")

    def _boolean_test(self):
        if self.value is None:
            return False
        else:
            return True

    if sys.version_info[0] > 2:
        def __bool__(self):
            return self._boolean_test()
    else:
        def __nonzero__(self):
            return self._boolean_test()

    def as_hff(self, parent_group, name="volume"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        group['latticeId'] = self.lattice_id
        group['value'] = self.value
        if self.transform_id is not None:
            group['transformId'] = self.transform_id
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        obj.lattice_id = hff_data['latticeId'][()]
        obj.value = hff_data['value'][()]
        if 'transformId' in hff_data:
            obj.transform_id = hff_data['transformId'][()]
        return obj


class SFFVolume(SFFType):
    """Class for represention 3-space dimension"""
    # attributes
    cols = SFFAttribute('cols', help="number of columns")
    rows = SFFAttribute('rows', help="number of rows")
    sections = SFFAttribute('sections', help="number of sections (sets of congruent row-column collections)")

    @property
    def value(self):
        return self.cols, self.rows, self.sections

    @value.setter
    def value(self, value):
        if len(value) == 3:
            self.cols, self.rows, self.sections = value
        else:
            raise SFFTypeError(value, "Iterable", message="should be of length 3")

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Dataset)
        obj = cls()
        obj.cols = hff_data[0]
        obj.rows = hff_data[1]
        obj.sections = hff_data[2]
        return obj


class SFFVolumeStructure(SFFVolume):
    gds_type = sff.volumeStructureType
    ref = "3D volume structure: cols, rows, sections"
    repr_string = "SFFVolumeStructure(cols={}, rows={}, sections={})"
    repr_args = ('cols', 'rows', 'sections')

    @property
    def voxel_count(self):
        """The number of voxels in this volume"""
        return self.cols * self.rows * self.sections


class SFFVolumeIndex(SFFVolume):
    gds_type = sff.volumeIndexType
    ref = "3D volume start index: cols, rows, sections"
    repr_string = "SFFVolumeIndex(cols={}, rows={}, sections={})"
    repr_args = ('cols', 'rows', 'sections')


class SFFLattice(SFFIndexType, SFFType):
    """Class representing 3D """
    gds_type = sff.latticeType
    ref = "3D lattice"
    repr_string = "SFFLattice(mode={}, endianness={}, size={}, start={}, data=<numpy.ndarray>)"
    repr_args = ('mode', 'endianness', 'size', 'start')
    lattice_id = 0

    index_attr = 'lattice_id'

    # attributes
    id = SFFAttribute('id', help="the ID for this lattice (referenced by 3D volumes)")
    mode = SFFAttribute('mode',
                        help="type of data for each voxel; valid values are: int8, uint8, int16, uint16, int32, "
                             "uint32, int64, uint64, float32, float64")
    endianness = SFFAttribute('endianness', help="endianness; either 'little' (default) or 'big'")
    # todo: redundant to have size and data when size should be inferred from data
    size = SFFAttribute('size', sff_type=SFFVolumeStructure, help="size of the lattice described using a "
                                                                  ":py:class:`sfftkrw.schema.SFFVolumeStructure` object")
    start = SFFAttribute('start', sff_type=SFFVolumeIndex, help="starting index of the lattices described using a"
                                                                ":py:class:`sfftkrw.schema.SFFVolumeIndex` object")
    data = SFFAttribute('data', help="data provided by a numpy array; the dimensions should correspond with those "
                                     "specified in the 'size' attribute")

    def __init__(self, *args, **kwargs):
        super(SFFLattice, self).__init__(*args, **kwargs)
        # ensure that data is bytes, not string
        if isinstance(self.data, _str):  # for python2: unicode, for python3: str
            # we should decode it using ASCII
            self.data = _encode(self.data, 'ASCII')
        if not self.is_encoded:
            # encode on create
            self.encode()

    @property
    def is_encoded(self):
        """Tells whether the data in the lattice is encoded or not"""
        if isinstance(self.data, _bytes):
            return True
        return False

    def encode(self):
        """Encode the numpy array provided in the initialiser

        Flatten -> Pack -> Zip -> Base64 encode
        """
        try:
            assert isinstance(self.data, np.ndarray)
        except AssertionError as a:
            print_date("Cannot encode data of type {}".format(type(self.data)))
            sys.exit(os.EX_DATAERR)
        format_string = "{}{}{}".format(ENDIANNESS[self.endianness], self.size.voxel_count, FORMAT_CHARS[self.mode])
        try:
            binpack = struct.pack(format_string, *self.data.flat)
            # del binlist
            self.data = None
            binzip = zlib.compress(binpack)
            del binpack
            bin64 = base64.b64encode(binzip)
            del binzip
            self.data = bin64
        except MemoryError:
            print_date("Out of memory exception. Please rerun with more memory.")
            self.data = None

    def decode(self):
        """Decode the data for processing

        Base64 decode -> Unzip -> Unpack -> Reshape
        """
        binzip = base64.b64decode(self.data)
        self.data = None
        binpack = zlib.decompress(binzip)
        del binzip
        _count = self.size.voxel_count
        bindata = struct.unpack("{}{}{}".format(ENDIANNESS[self.endianness], _count, FORMAT_CHARS[self.mode]), binpack)
        del binpack
        self.data = np.array(bindata).reshape(*self.size.value[::-1])
        del bindata
        # self.data = numpy.frombuffer(zlib.decompress(binzip)).reshape(*self.size.value)
        # del binzip

    @property
    def is_binary(self):
        """Quick check to see whether the 3D volume is binary or not"""
        voxel_values = set(self.data.flatten().tolist()).difference({0})
        if len(voxel_values) == 1:
            return True
        else:
            return False

    def as_hff(self, parent_group, name="{}"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name.format(self.id))
        group['mode'] = _decode(self.mode, 'utf-8')
        group['endianness'] = _decode(self.endianness, 'utf-8')
        group['size'] = self.size.value
        group['start'] = self.start.value
        group['data'] = self.data
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        mode_ = _decode(hff_data['mode'][()], 'utf-8')
        obj = cls(
            mode=mode_,
            endianness=_decode(hff_data['endianness'][()], 'utf-8'),
            size=SFFVolumeStructure.from_hff(hff_data['size']),
            start=SFFVolumeIndex.from_hff(hff_data['start']),
            data=_decode(hff_data['data'][()], 'utf-8'),
        )
        return obj


class SFFLatticeList(SFFListType, SFFType):
    """A container for lattice objects"""
    gds_type = sff.latticeListType
    ref = "Container for 3D lattices"
    repr_string = "Container with {} 3D lattices"
    repr_args = ("len()",)
    iter_attr = ('lattice', SFFLattice)
    iter_dict = _dict()

    def add_lattice(self, l):
        """Add a lattice to the list of lattices

        Convert the data from bytes to unicode before adding

        :param l: a lattice object
        :type l: :py:class:`SFFLattice`
        """
        if isinstance(l, SFFLattice):
            # convert data from bytes to unicode
            l.data = _decode(l.data, 'utf-8')
            self._local.add_lattice(l._local)
        else:
            raise SFFTypeError(l, SFFLattice)

    def as_hff(self, parent_group, name='lattices'):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        for lattice in self:
            group = lattice.as_hff(group)
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        for lattice_id in hff_data:
            L = SFFLattice.from_hff(hff_data[lattice_id])
            L.id = int(lattice_id)
            obj.add_lattice(L)
        return obj


class SFFShape(SFFIndexType, SFFType):
    """Base shape class"""
    repr_string = "{} {}"
    repr_args = ('ref', 'id')
    shape_id = 0
    index_attr = 'shape_id'
    index_in_super = True

    # attributes
    id = SFFAttribute('id', help="the ID of this shape")
    transform_id = SFFAttribute('transformId', help="the transform applied to this shape to position it in the space")
    attribute = SFFAttribute('attribute', help="extra attribute information e.g. 'FOM'")

    @classmethod
    def update_counter(cls, value):
        """Update the index for all subclasses sequentially for sibling classes

        This method works alongside the `index_in_super` class attribute.

        The superclass must specify this method to ensure correct sequencing of shared indices.
        """
        SFFShape.shape_id = value


class SFFCone(SFFShape):
    """Cone shape class"""
    gds_type = sff.cone
    ref = "cone"

    # attributes
    height = SFFAttribute('height', help="cone height")
    bottom_radius = SFFAttribute('bottomRadius', help="cone bottom radius")

    # def __new__(cls, *args, **kwargs):
    #     cls.shape_id = super(SFFCone, cls).shape_id + 1
    #     return super(SFFCone, cls).__new__(cls, *args, **kwargs)

    def __init__(self, *args, **kwargs):
        super(SFFCone, self).__init__(*args, **kwargs)
        # if 'id' in kwargs:
        #     self._local.id = kwargs['id']
        #     SFFShape.shape_id = self.shape_id
        # else:
        #     self._local.id = self.shape_id
        #     SFFShape.shape_id = self.shape_id
        self._local.original_tagname_ = self.ref


class SFFCuboid(SFFShape):
    """Cuboid shape class"""
    gds_type = sff.cuboid
    ref = "cuboid"

    # attributes
    x = SFFAttribute('x', help="length in x")
    y = SFFAttribute('y', help="length in y")
    z = SFFAttribute('z', help="length in z")

    # def __new__(cls, *args, **kwargs):
    #     cls.shape_id = super(SFFCuboid, cls).shape_id + 1
    #     return super(SFFCuboid, cls).__new__(cls)

    def __init__(self, *args, **kwargs):
        super(SFFCuboid, self).__init__(*args, **kwargs)
        # if 'id' in kwargs:
        #     self._local.id = kwargs['id']
        #     SFFShape.shape_id = self.shape_id
        # else:
        #     self._local.id = self.shape_id
        #     SFFShape.shape_id = self.shape_id
        self._local.original_tagname_ = self.ref


class SFFCylinder(SFFShape):
    """Cylinder shape class"""
    gds_type = sff.cylinder
    ref = "cylinder"

    # attributes
    height = SFFAttribute('height', help="cylinder height")
    diameter = SFFAttribute('diameter', help="cylinder diameter")

    # def __new__(cls, *args, **kwargs):
    #     cls.shape_id = super(SFFCylinder, cls).shape_id + 1
    #     return super(SFFCylinder, cls).__new__(cls)

    def __init__(self, *args, **kwargs):
        super(SFFCylinder, self).__init__(*args, **kwargs)
        # if 'id' in kwargs:
        #     self._local.id = kwargs['id']
        #     SFFShape.shape_id = self.shape_id
        # else:
        #     self._local.id = self.shape_id
        #     SFFShape.shape_id = self.shape_id
        self._local.original_tagname_ = self.ref


class SFFEllipsoid(SFFShape):
    """Ellipsoid shape class"""
    gds_type = sff.ellipsoid
    ref = "ellipsoid"

    # attributes
    x = SFFAttribute('x', help="length in x")
    y = SFFAttribute('y', help="length in y")
    z = SFFAttribute('z', help="length in z")

    # def __new__(cls, *args, **kwargs):
    #     cls.shape_id = super(SFFEllipsoid, cls).shape_id + 1
    #     return super(SFFEllipsoid, cls).__new__(cls)

    def __init__(self, *args, **kwargs):
        super(SFFEllipsoid, self).__init__(*args, **kwargs)
        # if 'id' in kwargs:
        #     self._local.id = kwargs['id']
        #     SFFShape.shape_id = self.shape_id
        # else:
        #     self._local.id = self.shape_id
        #     SFFShape.shape_id = self.shape_id
        self._local.original_tagname_ = self.ref


class SFFShapePrimitiveList(SFFListType, SFFType):
    """Container for shapes"""
    gds_type = sff.shapePrimitiveListType
    ref = 'shape_primitive_list'
    repr_string = "SFFShapePrimitiveList()"
    iter_attr = ('shapePrimitive', SFFShape)

    def __init__(self, *args, **kwargs):
        # reset id
        SFFShape.reset_id()
        super(SFFShapePrimitiveList, self).__init__(*args, **kwargs)

    def add_shape(self, s):
        """Add the provide shape into this shape container

        :param s: a shape object
        :type s: :py:class:`SFFShape`
        :raises SFFTypeError: if ``s`` is of the wrong type
        """
        if isinstance(s, SFFShape):
            self._local.shapePrimitive.append(s._local)
        else:
            raise SFFTypeError(s, SFFShape)

    def __len__(self):
        return len(self._local.shapePrimitive)

    def __getitem__(self, index):
        return self._shape_cast(self._local.shapePrimitive[index])

    @staticmethod
    def _shape_cast(shape):
        if isinstance(shape, sff.ellipsoid):
            return SFFEllipsoid(shape)
        elif isinstance(shape, sff.cuboid):
            return SFFCuboid(shape)
        elif isinstance(shape, sff.cylinder):
            return SFFCylinder(shape)
        elif isinstance(shape, sff.cone):
            return SFFCone(shape)
        else:
            raise TypeError("unknown shape type '{}'".format(type(shape)))

    def __iter__(self):
        return iter(list(map(self._shape_cast, self._local.shapePrimitive)))

    def _shape_count(self, shape_type):
        return len(list(filter(lambda s: isinstance(s, shape_type), self._local.shapePrimitive)))

    @property
    def num_ellipsoids(self):
        """The number of ellipsoids in this container"""
        return self._shape_count(sff.ellipsoid)

    @property
    def num_cuboids(self):
        """The number of cuboids in this container"""
        return self._shape_count(sff.cuboid)

    @property
    def num_cylinders(self):
        """The number of cylinders in this container"""
        return self._shape_count(sff.cylinder)

    @property
    def num_cones(self):
        """The number of cones in this container"""
        return self._shape_count(sff.cone)

    #     @property
    #     def num_subtomogram_averages(self):
    #         return self._shape_count(sff.subtomogramAverage)

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        if "ellipsoids" in hff_data:
            for ellipsoid in hff_data["ellipsoids"]:
                e = SFFEllipsoid()
                e.id = int(ellipsoid['id'])
                e.x = float(ellipsoid['x'])
                e.y = float(ellipsoid['y'])
                e.z = float(ellipsoid['z'])
                e.transform_id = int(ellipsoid['transformId'])
                if not np.isnan(ellipsoid['attribute']):
                    e.attribute = float(ellipsoid['attribute'])
                obj.add_shape(e)
        if "cones" in hff_data:
            for cone in hff_data["cones"]:
                c = SFFCone()
                c.id = int(cone['id'])
                c.bottom_radius = float(cone['bottomRadius'])
                c.height = float(cone['height'])
                c.transform_id = int(cone['transformId'])
                if not np.isnan(cone['attribute']):
                    c.attribute = float(cone['attribute'])
                obj.add_shape(c)
        if "cuboids" in hff_data:
            for cuboid in hff_data["cuboids"]:
                c = SFFCuboid()
                c.id = int(cuboid['id'])
                c.x = float(cuboid['x'])
                c.y = float(cuboid['y'])
                c.z = float(cuboid['z'])
                c.transform_id = int(cuboid['transformId'])
                if not np.isnan(cuboid['attribute']):
                    c.attribute = float(cuboid['attribute'])
                obj.add_shape(c)
        if "cylinders" in hff_data:
            for cylinder in hff_data["cylinders"]:
                c = SFFCylinder()
                c.id = int(cylinder['id'])
                c.height = float(cylinder['height'])
                c.diameter = float(cylinder['diameter'])
                c.transform_id = int(cylinder['transformId'])
                if not np.isnan(cylinder['attribute']):
                    c.attribute = float(cylinder['attribute'])
                obj.add_shape(c)
        return obj


class SFFVertex(SFFIndexType, SFFType):
    """Single vertex"""
    gds_type = sff.vertexType
    ref = "Vertex"
    repr_string = "{} vertex {}: ({}, {}, {})"
    repr_args = ('designation', 'vID', 'x', 'y', 'z')
    vertex_id = 0
    index_attr = 'vertex_id'

    # attributes
    # fixme: rename `vID` to `id` for simplicity in schema
    vID = SFFAttribute('vID', help="vertex ID; referenced by polygons")
    designation = SFFAttribute('designation', help="type of vertex ('surface' (default) or 'normal')")
    x = SFFAttribute('x', help="x co-ordinate")
    y = SFFAttribute('y', help="y co-ordinate")
    z = SFFAttribute('z', help="z co-ordinate")

    @property
    def point(self):
        """The co-ordinates for this vertex"""
        return self.x, self.y, self.z

    @point.setter
    def point(self, p):
        if isinstance(p, tuple):
            if len(p) == 3:
                self.x, self.y, self.z = p
            else:
                raise TypeError("point does not have three values")
        else:
            raise SFFTypeError(p, tuple)


class SFFPolygon(SFFIndexType, SFFType):
    """Single polygon"""
    gds_type = sff.polygonType
    ref = "Polygon"
    repr_string = "Polygon {}"
    repr_args = ('PID',)
    iter_attr = ('v', int)
    polygon_id = 0
    iter_dict = _dict()
    index_attr = 'polygon_id'

    # attributes
    # fixme: rename `PID` to `id` for simplicity in schema
    PID = SFFAttribute('PID', help="the ID for this polygon")

    @property
    def vertex_ids(self):
        """An iterable of vertex IDs of this polygon"""
        return [v for v in self]

    def add_vertex(self, v):
        """Add the vertex ID to this polygon

        :param int v: a vertex ID
        """
        if isinstance(v, int):
            self._local.add_v(v)
        else:
            raise SFFTypeError(v, int)


class SFFVertexList(SFFListType, SFFType):
    """List of vertices"""
    gds_type = sff.vertexListType
    ref = "List of vertices"
    iter_attr = ('v', SFFVertex)

    def __init__(self, *args, **kwargs):
        super(SFFVertexList, self).__init__(*args, **kwargs)
        self._vertex_dict = {v.vID: v for v in map(SFFVertex, self._local.v)}

    @property
    def num_vertices(self):
        """The number of vertices in this vertex container"""
        return len(self)

    def __str__(self):
        return "Vertex dict with {} vertices".format(len(self))

    def __len__(self):
        return len(self._local.v)

    def __iter__(self):
        return iter(self._vertex_dict.values())

    @property
    def vertex_ids(self):
        """Iterable of vertex IDs contained in this vertex container"""
        return iter(self._vertex_dict.keys())

    def __getitem__(self, vertex_id):
        return self._vertex_dict[vertex_id]

    def add_vertex(self, v):
        """Add the provided vertex to this vertex container

        :param v: a vertex object
        :type v: :py:class:`SFFVertex`
        :raises SFFTypeError: if ``v`` is of the wrong type
        """
        if isinstance(v, SFFVertex):
            self._local.add_v(v._local)
            self._local.numVertices = self.num_vertices
        else:
            raise SFFTypeError(v, SFFVertex)

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Dataset)
        obj = cls()
        for vertex in hff_data:
            obj.add_vertex(
                SFFVertex(
                    vID=vertex['vID'],
                    designation=vertex['designation'],
                    x=float(vertex['x']),
                    y=float(vertex['y']),
                    z=float(vertex['z'])
                )
            )
        return obj


class SFFPolygonList(SFFListType, SFFType):
    """List of polygons"""
    gds_type = sff.polygonListType
    ref = "List of polygons"
    repr_string = "Polygon list with {} polygons"
    repr_args = ('len()',)
    iter_attr = ('P', SFFPolygon)

    def __init__(self, *args, **kwargs):
        super(SFFPolygonList, self).__init__(*args, **kwargs)
        self._polygon_dict = {P.PID: P for P in list(map(SFFPolygon, self._local.P))}

    @property
    def num_polygons(self):
        """The number of polygons in this list of polygons"""
        return len(self)

    def __len__(self):
        return len(self._local.P)

    def __iter__(self):
        return iter(self._polygon_dict.values())

    @property
    def polygon_ids(self):
        """An iterable over the polygon IDs of the contained polygons"""
        return self.__iter__()

    def __getitem__(self, polygon_id):
        return self._polygon_dict[polygon_id]

    def __str__(self):
        return "Polygon list with {} polygons".format(len(self))

    def add_polygon(self, P):
        """Add a polygon to this polygon container

        :param p: a polygon object
        :type p: :py:class:`SFFPolygon`
        """
        if isinstance(P, SFFPolygon):
            self._local.add_P(P._local)
            self._local.numPolygons = self.num_polygons
        else:
            raise SFFTypeError(P, SFFPolygon)

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Dataset)
        obj = cls()
        for polygon in hff_data:
            P = SFFPolygon()
            P.PID = int(polygon['PID'])
            [P.add_vertex(int(_)) for _ in polygon['v']]
            obj.add_polygon(P)
        return obj


class SFFMesh(SFFIndexType, SFFType):
    """Single mesh"""
    gds_type = sff.meshType
    ref = "Mesh"
    repr_string = "Mesh {} with {} and {}"
    repr_args = ('id', 'vertices', 'polygons')
    mesh_id = 0
    index_attr = 'mesh_id'

    # attributes
    id = SFFAttribute('id')
    vertices = SFFAttribute('vertexList', sff_type=SFFVertexList,
                            help="a list of vertices (object of class :py:class:`sfftkrw.schema.SFFVertexList`)")
    polygons = SFFAttribute('polygonList', sff_type=SFFPolygonList,
                            help="a list of derived polygons (object of class :py:class:`sfftkrw.schema.SFFPolygonList`)")
    transform_id = SFFAttribute('transformId', help="a transform applied to the mesh")

    @property
    def num_vertices(self):
        """The number of vertices in this mesh"""
        return len(self.vertices)

    @property
    def num_polygons(self):
        """The number of polygons in this mesh"""
        return len(self.polygons)

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        obj.vertices = SFFVertexList.from_hff(hff_data['vertices'])
        obj.polygons = SFFPolygonList.from_hff(hff_data['polygons'])
        return obj


class SFFMeshList(SFFListType, SFFType):
    """Mesh list representation"""
    gds_type = sff.meshListType
    ref = "mesh_list"
    repr_string = "Mesh list with {} meshe(s)"
    repr_args = ('len()',)
    iter_attr = ('mesh', SFFMesh)
    iter_dict = _dict()

    def add_mesh(self, m):
        """Add a mesh into the list of meshes

        :param m: a mesh object
        :type m: :py:class:`SFFMesh`
        """
        if isinstance(m, SFFMesh):
            self._local.add_mesh(m._local)
        else:
            raise SFFType(SFFMesh)

    def as_hff(self, parent_group, name="meshes"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        # structures
        vlen_str = h5py.special_dtype(vlen=str)
        vertex_array = h5py.special_dtype(vlen=np.dtype('u4'))  # create a variable-length for vertices
        for mesh in self:
            # /sff/segments/1/meshes/0 - mesh 0
            h_mesh = group.create_group("{}".format(mesh.id))
            # /sff/segments/1/meshes/0/vertices
            h_v = h_mesh.create_dataset(
                "vertices",
                (mesh.num_vertices,),
                dtype=[
                    ('vID', 'u8'),
                    ('designation', vlen_str),
                    ('x', 'f4'),
                    ('y', 'f4'),
                    ('z', 'f4'),
                ],
                #                 compression="gzip",
            )
            # load vertex data
            i = 0
            for vertex in mesh.vertices:
                h_v[i] = (vertex.vID, vertex.designation, vertex.x, vertex.y, vertex.z)
                i += 1
            # /sff/segments/1/meshes/0/polygons
            h_P = h_mesh.create_dataset(
                "polygons",
                (mesh.num_polygons,),
                dtype=[
                    ('PID', 'u8'),
                    ('v', vertex_array),
                ],
                #                 compression="gzip",
            )
            # Â load polygon data
            j = 0
            for polygon in mesh.polygons:
                h_P[j] = (polygon.PID, np.array(polygon.vertex_ids))
                j += 1
            if mesh.transform_id:
                h_mesh["transformId"] = mesh.transform_id
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        for mesh_id in hff_data:
            M = SFFMesh.from_hff(hff_data["{}".format(mesh_id)])
            M.id = int(mesh_id)
            obj.add_mesh(M)
        return obj


class SFFSegment(SFFIndexType, SFFType):
    """Class that encapsulates segment data"""
    gds_type = sff.segmentType
    ref = "Segment"
    repr_string = "Segment {}"
    repr_args = ('id',)
    segment_id = 1
    segment_parentID = 0

    index_attr = 'segment_id'
    start_at = 1

    # attributes
    id = SFFAttribute('id',
                      help="the ID for this segment; segment IDs begin at 1 with the value of 0 implying the segmentation i.e. all segments are children of the root segment (the segmentation)")
    parentID = SFFAttribute('parentID',
                            help="the ID for the segment that contains this segment; defaults to 0 (the whole segmentation)")
    biological_annotation = SFFAttribute('biologicalAnnotation', sff_type=SFFBiologicalAnnotation,
                                         help="the biological annotation for this segment; described using a :py:class:`sfftkrw.schema.SFFBiologicalAnnotation` object")
    complexes_and_macromolecules = SFFAttribute('complexesAndMacromolecules', sff_type=SFFComplexesAndMacromolecules,
                                                help="the complexes and macromolecules associated with this segment; described using a :py:class:`sfftkrw.schema.SFFComplexesAndMacromolecules` object")
    colour = SFFAttribute('colour', sff_type=SFFRGBA,
                          help="this segments colour; described using a :py:class:`sfftkrw.schema.SFFRGBA` object")
    meshes = SFFAttribute('meshList', sff_type=SFFMeshList,
                          help="the list of meshes (if any) that describe this segment; a :py:class:`sfftkrw.schema.SFFMeshList` object")
    volume = SFFAttribute('threeDVolume', sff_type=SFFThreeDVolume,
                          help="the 3D volume (if any) that describes this segment; a :py:class:`sfftkrw.schema.SFFThreeDVolume` object ")
    shapes = SFFAttribute('shapePrimitiveList', sff_type=SFFShapePrimitiveList,
                          help="the list of shape primitives that describe this segment; a :py:class:`sfftkrw.schema.SFFShapePrimitiveList` object")

    # def __new__(cls, *args, **kwargs):
    #     cls.segment_id += 1
    #     return super(SFFSegment, cls).__new__(cls)

    def __init__(self, *args, **kwargs):
        super(SFFSegment, self).__init__(*args, **kwargs)
        # parentID
        # unlink segment_id, parentID is not managed by `SFFIndexType`
        if 'parentID' in kwargs:
            self._local.parentID = kwargs['parentID']
        else:
            self._local.parentID = self.segment_parentID

    def as_hff(self, parent_group, name="{}"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name.format(self.id))
        group['parentID'] = self.parentID
        # add annotation data
        if self.biological_annotation:
            group = self.biological_annotation.as_hff(group)
        if self.complexes_and_macromolecules:
            group = self.complexes_and_macromolecules.as_hff(group)
        if self.colour:
            group = self.colour.as_hff(group)
        # add segmentation data
        if self.meshes:
            group = self.meshes.as_hff(group)
        if self.shapes:
            # /sff/segments/1/shapes
            h_shapes = group.create_group("shapes")
            # /sff/segments/1/shapes/ellipsoids
            h_ell = h_shapes.create_dataset(
                "ellipsoids",
                (self.shapes.num_ellipsoids,),
                dtype=[
                    ('id', 'u4'),
                    ('x', 'f4'),
                    ('y', 'f4'),
                    ('z', 'f4'),
                    ('transformId', 'u4'),
                    ('attribute', 'f4'),
                ]
            )
            h_cub = h_shapes.create_dataset(
                "cuboids",
                (self.shapes.num_cuboids,),
                dtype=[
                    ('id', 'u4'),
                    ('x', 'f4'),
                    ('y', 'f4'),
                    ('z', 'f4'),
                    ('transformId', 'u4'),
                    ('attribute', 'f4'),
                ]
            )

            h_cyl = h_shapes.create_dataset(
                "cylinders",
                (self.shapes.num_cylinders,),
                dtype=[
                    ('id', 'u4'),
                    ('height', 'f4'),
                    ('diameter', 'f4'),
                    ('transformId', 'u4'),
                    ('attribute', 'f4'),
                ]
            )

            h_con = h_shapes.create_dataset(
                "cones",
                (self.shapes.num_cones,),
                dtype=[
                    ('id', 'u4'),
                    ('height', 'f4'),
                    ('bottomRadius', 'f4'),
                    ('transformId', 'u4'),
                    ('attribute', 'f4'),
                ]
            )
            i = 0  # ellipsoid
            j = 0  # cuboid
            k = 0  # cylinder
            m = 0  # cone
            # n = 0 # subtomogram average
            for shape in self.shapes:
                if shape.ref == "Ellipsoid":
                    h_ell[i] = (shape.id, shape.x, shape.y, shape.z, shape.transform_id,
                                shape.attribute if hasattr(shape, 'attribute') else None)
                    i += 1
                elif shape.ref == "Cuboid":
                    h_cub[j] = (shape.id, shape.x, shape.y, shape.z, shape.transform_id,
                                shape.attribute if hasattr(shape, 'attribute') else None)
                    j += 1
                elif shape.ref == "Cylinder":
                    h_cyl[k] = (shape.id, shape.height, shape.diameter, shape.transform_id,
                                shape.attribute if hasattr(shape, 'attribute') else None)
                    k += 1
                elif shape.ref == "Cone":
                    h_con[m] = (shape.id, shape.height, shape.bottom_radius, shape.transform_id,
                                shape.attribute if hasattr(shape, 'attribute') else None)
                    m += 1
                # elif shape.ref == "Subtomogram average":
                #     warn("Unimplemented portion")
        if self.volume:
            # /sff/segments/1/volume
            group = self.volume.as_hff(group)
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        obj.parentID = int(hff_data['parentID'][()])
        if "biologicalAnnotation" in hff_data:
            obj.biological_annotation = SFFBiologicalAnnotation.from_hff(hff_data["biologicalAnnotation"])
        if "complexesAndMacromolecules" in hff_data:
            obj.complexes_and_macromolecules = SFFComplexesAndMacromolecules.from_hff(
                hff_data["complexesAndMacromolecules"])
        if "colour" in hff_data:
            obj.colour = SFFRGBA.from_hff(hff_data)
        if "meshes" in hff_data:
            obj.meshes = SFFMeshList.from_hff(hff_data["meshes"])
        if "shapes" in hff_data:
            obj.shapes = SFFShapePrimitiveList.from_hff(hff_data["shapes"])
        if "volume" in hff_data:
            obj.volume = SFFThreeDVolume.from_hff(hff_data["volume"])
        return obj


class SFFSegmentList(SFFListType, SFFType):
    """Container for segments"""
    gds_type = sff.segmentListType
    ref = "segment_list"
    repr_string = "Segment container"
    iter_attr = ('segment', SFFSegment)
    iter_dict = _dict()

    # def __init__(self, *args, **kwargs):
    #     # reset id
    #     SFFSegment.reset_id()
    #     super(SFFSegmentList, self).__init__(*args, **kwargs)

    def add_segment(self, s):
        """Add a segment to this segment container

        :param s: a segment object
        :type s: :py:class:`SFFSegment`
        :raises SFFTypeError: if ``s`` is of the wrong type
        """
        if isinstance(s, SFFSegment):
            self._local.add_segment(s._local)
        else:
            raise SFFTypeError(s, SFFSegment)

    def as_hff(self, parent_group, name="segments"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        for segment in self:
            group = segment.as_hff(group)
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        for segment_id in hff_data:
            S = SFFSegment.from_hff(hff_data[segment_id])
            S.id = int(segment_id)
            obj.add_segment(S)
        return obj


class SFFTransformationMatrix(SFFIndexType, SFFType):
    """Transformation matrix transform"""
    gds_type = sff.transformationMatrixType
    ref = "transformation_matrix"
    transform_id = 0
    index_attr = 'transform_id'

    # attributes
    id = SFFAttribute('id', help="an ID for this transform")
    rows = SFFAttribute('rows', help="the number of rows in this matrix")
    cols = SFFAttribute('cols', help="the number of columns in this matrix")
    data = SFFAttribute('data', help="the data in this matrix")

    # todo: work with numpy arrays transparently

    def __new__(cls, *args, **kwargs):
        cls.transform_id += 1
        return super(SFFTransformationMatrix, cls).__new__(cls)

    def __init__(self, *args, **kwargs):
        super(SFFTransformationMatrix, self).__init__(*args, **kwargs)
        # override id if it is included
        if 'id' in kwargs:
            self._local.id = kwargs['id']
        else:
            self._local.id = self.transform_id

        self._local.original_tagname_ = self.ref

    @property
    def data_array(self):
        """The data in this matrix as an array"""
        data_list = list(map(float, self.data.split(' ')))
        data_array = np.array(data_list).reshape(self.rows, self.cols)
        return data_array

    # TODO: a setter for the above attribute

    def __str__(self):
        return (("[" + "{:.4f} " * self.cols + "]\n") * self.rows).format(*map(float, self.data.split(' ')))


class SFFTransformList(SFFListType, SFFType):
    """Container for transforms"""
    gds_type = sff.transformListType
    ref = "Transform list"
    repr_string = "List of transforms"
    iter_attr = ('transform', SFFTransformationMatrix)
    iter_dict = _dict()

    def __init__(self, *args, **kwargs):
        # a new container of transforms needs the transform ID reset
        SFFTransformationMatrix.reset_id()
        super(SFFTransformList, self).__init__(*args, **kwargs)

    @property
    def transformation_matrix_count(self):
        """The number of :py:class:`SFFTransformationMatrix` objects in this transform container"""
        return len(self._local.transform)

    def add_transform(self, T):
        """Add the specified transform to this transform container"""
        if isinstance(T, SFFTransformationMatrix):
            self._local.add_transform(T._local)
        else:
            raise SFFTypeError(T, SFFTransformationMatrix)

    def check_transformation_matrix_homogeneity(self):
        """Helper method to check transformation matrix homogeneity

        If the transformation matrices are not homogeneous then we cannot use
        structured arrays in numpy :'(
        """
        transformation_matrices_similar = True  # assume they are all similar
        first = True
        rows = None
        cols = None
        for transform in self:
            if transform.ref == "transformation_matrix":
                if first:
                    rows = transform.rows
                    cols = transform.cols
                    first = False
                    continue
                else:
                    if transform.rows != rows or transform.cols != cols:
                        transformation_matrices_similar = False
                        break
        return transformation_matrices_similar, rows, cols

    def as_hff(self, parent_group, name="transforms"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        # we need to check whether all transformation_matrices are of the same dimension
        # what we need to know:
        # - rows
        # Â - cols
        # if they are then we just use rows and cols
        # else we should
        transformation_matrices_similar, rows, cols = self.check_transformation_matrix_homogeneity()
        if self.transformation_matrix_count:
            if transformation_matrices_similar:
                h_tM = group.create_dataset(
                    "transformationMatrix",
                    (self.transformation_matrix_count,),
                    dtype=[
                        ('id', 'u4'),
                        ('rows', 'u1'),
                        ('cols', 'u1'),
                        ('data', 'f4', (rows, cols)),
                    ]
                )
            else:
                h_tM = group.create_group("transformationMatrix")
        i = 0  # h_tM index
        j = 0  # h_cEA index
        k = 0  # h_vVR index
        for transform in self:
            if transform.ref == "transformation_matrix":
                if transformation_matrices_similar:
                    h_tM[i] = (transform.id, transform.rows, transform.cols, transform.data_array)
                    i += 1
                else:
                    rows_, cols_ = transform.data_array.shape
                    tM = h_tM.create_dataset(
                        "{}".format(transform.id),
                        (1,),
                        dtype=[
                            ('id', 'u4'),
                            ('rows', 'u1'),
                            ('cols', 'u1'),
                            ('data', 'f4', (rows_, cols_)),
                        ]
                    )
                    tM[0] = (transform.id, transform.rows, transform.cols, transform.data_array)
                    i += 1
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        if "transformationMatrix" in hff_data:
            for _transform in hff_data['transformationMatrix']:
                if isinstance(hff_data['transformationMatrix'], h5py.Group):
                    transform = hff_data['transformationMatrix'][_transform][0]
                else:
                    transform = _transform
                T = SFFTransformationMatrix()
                T.id = transform['id']
                T.rows = transform['rows']
                T.cols = transform['cols']
                T.data = " ".join(map(str, transform['data'].flatten()))
                obj.add_transform(T)
        return obj


class SFFSoftware(SFFType):
    """Class definition for specifying software used to create this segmentation

    .. py:attribute:: name

        The name of the software used

    .. py:attribute:: version

        The version string

    .. py:attribute:: processing_details

        Details of how the segmentation was produced
    """
    gds_type = sff.softwareType
    ref = "Software"
    repr_string = "Software object"

    # attributes
    name = SFFAttribute('name', help="the software/programme's name")
    version = SFFAttribute('version', help="the version used")
    processing_details = SFFAttribute('processingDetails',
                                      help="a description of how the data was processed to produce the segmentation")

    def as_hff(self, parent_group, name="software"):
        """Return the data of this object as an HDF5 group in the given parent group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        group['name'] = self.name if self.name else ''
        group['version'] = _str(self.version) if self.version else ''
        if self.processing_details:
            group['processingDetails'] = self.processing_details
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Return an SFFType object given an HDF5 object"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        obj.name = _decode(hff_data['name'][()], 'utf-8')
        obj.version = _decode(hff_data['version'][()], 'utf-8')
        if 'processingDetails' in hff_data:
            obj.processing_details = _decode(hff_data['processingDetails'][()], 'utf-8')
        return obj


class SFFBoundingBox(SFFType):
    """Dimensions of bounding box"""
    # Â config
    gds_type = sff.boundingBoxType
    ref = "Bounding box"
    repr_string = "Bounding box: ({}, {}, {}, {}, {}, {})"
    repr_args = ('xmin', 'xmax', 'ymin', 'ymax', 'zmin', 'zmax')

    # attributes
    xmin = SFFAttribute('xmin', help="minimum x co-ordinate value")
    xmax = SFFAttribute('xmax', help="maximum x co-ordinate value")
    ymin = SFFAttribute('ymin', help="minimum y co-ordinate value")
    ymax = SFFAttribute('ymax', help="maximum y co-ordinate value")
    zmin = SFFAttribute('zmin', help="minimum z co-ordinate value")
    zmax = SFFAttribute('zmax', help="maximum z co-ordinate value")

    # methods
    def as_hff(self, parent_group, name="boundingBox"):
        """Bounding box as HDF5 group"""
        assert isinstance(parent_group, h5py.Group)
        group = parent_group.create_group(name)
        group['xmin'] = self.xmin
        group['xmax'] = self.xmax
        group['ymin'] = self.ymin
        group['ymax'] = self.ymax
        group['zmin'] = self.zmin
        group['zmax'] = self.zmax
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Bounding box from HDF5 group"""
        assert isinstance(hff_data, h5py.Group)
        obj = cls()
        obj.xmin = hff_data['xmin'][()]
        obj.xmax = hff_data['xmax'][()]
        obj.ymin = hff_data['ymin'][()]
        obj.ymax = hff_data['ymax'][()]
        obj.zmin = hff_data['zmin'][()]
        obj.zmax = hff_data['zmax'][()]
        return obj


# todo: double-check this
class SFFGlobalExternalReferences(SFFExternalReferences):
    """Container for global external references"""
    gds_type = sff.globalExternalReferencesType
    ref = "global_external_reference"
    repr_string = "SFFGlobalExternalReference(<list_of_{}_external_references>)"
    repr_args = ('len()', )


# class SFFGlobalExternalReferences(SFFListType, SFFType):
#     """Container for global external references"""
#     gds_type = sff.globalExternalReferencesType
#     ref = "global_external_reference"
#     repr_string = "Global external reference list with {} reference(s)"
#     repr_args = ('len()',)
#     iter_attr = ('ref', SFFExternalReference)
#     iter_dict = _dict()
#
#     # methods
#     def add_external_reference(self, e_r):
#         """Add the specified external reference object to this container
#
#         :param e_r: an external reference object
#         :type e_r: :py:class:`SFFExternalReference`
#         """
#         if isinstance(e_r, SFFExternalReference):
#             self._local.add_ref(e_r._local)
#         else:
#             raise SFFTypeError(e_r, SFFExternalReference)
#
#     def insert_external_reference(self, e_r, index):
#         """Insert the specified external reference object at the specified index
#
#         :param e_r: an external reference object
#         :type e_r: :py:class:`SFFExternalReference`
#         :param int index: the index to insert to; bumps all other external references down the list
#         """
#         if isinstance(e_r, SFFExternalReference) and isinstance(index, int):
#             self._local.insert_ref_at(index, e_r._local)
#         else:
#             if not isinstance(e_r, SFFExternalReference):
#                 raise SFFTypeError(e_r, SFFExternalReference)
#             elif not isinstance(index, int):
#                 raise SFFTypeError(index, int)
#
#     def replace_external_reference(self, e_r, index):
#         """Replace the external reference at ``index`` with the specified external reference
#
#         :param e_r: an external reference object
#         :type e_r: :py:class:`SFFExternalReference`
#         :param int index: the index to replace at
#         """
#         if isinstance(e_r, SFFExternalReference) and isinstance(index, int):
#             self._local.replace_ref_at(index, e_r._local)
#         else:
#             if not isinstance(e_r, SFFExternalReference):
#                 raise SFFTypeError(e_r, SFFExternalReference)
#             elif not isinstance(index, int):
#                 raise SFFTypeError(index, int)

class SFFSegmentation(SFFType):
    """Adapter class to make using the output of ``generateDS`` easier to use"""
    gds_type = sff.segmentation
    ref = "Segmentation"
    repr_string = ""

    # attributes
    name = SFFAttribute('name', help="the name of this segmentation")
    version = SFFAttribute('version', help="EMDB-SFF version")
    software = SFFAttribute(
        'software',
        sff_type=SFFSoftware,
        help="the software details used to generate this segmentationa :py:class:`sfftkrw.schema.SFFSoftware` object"
    )
    primary_descriptor = SFFAttribute(
        'primaryDescriptor',
        help="the main type of representation used for this segmentation; "
             "can be one of 'meshList', 'shapePrimitiveList' or 'threeDVolume'"
    )
    transforms = SFFAttribute(
        'transformList',
        sff_type=SFFTransformList,
        help="a list of transforms; a :py:class:`sfftkrw.schema.SFFTransformList` object"
    )
    bounding_box = SFFAttribute(
        'boundingBox',
        sff_type=SFFBoundingBox,
        help="the bounding box in which the segmentation sits; a :py:class:`sfftkrw.schema.SFFBoundingBox` object"
    )
    global_external_references = SFFAttribute(
        'globalExternalReferences',
        sff_type=SFFGlobalExternalReferences,
        help="a list of external references that apply to the whole segmentation (global); "
             "a :py:class:`sfftkrw.schema.SFFGlobalExternalReferences` object"
    )
    segments = SFFAttribute(
        'segmentList',
        sff_type=SFFSegmentList,
        help="the list of annotated segments; a :py:class:`sfftkrw.schema.SFFSegmentList` object"
    )
    lattices = SFFAttribute(
        'latticeList',
        sff_type=SFFLatticeList,
        help="the list of lattices (if any) containing 3D volumes referred to; "
             "a :py:class:`sfftkrw.schema.SFFLatticeList` object"
    )
    details = SFFAttribute(
        'details', help="any other details about this segmentation (free text)")

    @classmethod
    def from_file(cls, fn):
        """Instantiate an :py:class:`SFFSegmentations` object from a file name

        The file suffix determines how the data is extracted.

        :param str fn: name of a file hosting an EMDB-SFF-structured segmentation
        :return seg: the corresponding :py:class:`SFFSegmentation` object
        :rtype seg: :py:class:`SFFSegmentation`
        """
        seg = cls()
        if re.match(r'.*\.sff$', fn, re.IGNORECASE):
            try:
                seg._local = sff.parse(fn, silence=True)
            except IOError:
                print_date("File {} not found".format(fn))
                sys.exit(os.EX_IOERR)
        elif re.match(r'.*\.hff$', fn, re.IGNORECASE):
            with h5py.File(fn, 'r') as h:
                seg._local = seg.from_hff(h)._local
        elif re.match(r'.*\.json$', fn, re.IGNORECASE):
            seg._local = seg.from_json(fn)._local
        else:
            print_date("Invalid EMDB-SFF file name: {}".format(fn))
            sys.exit(os.EX_USAGE)
        return seg

    @property
    def num_global_external_references(self):
        """The number of global external references"""
        return len(self.global_external_references)

    def as_hff(self, parent_group, name=None):
        """Return the data of this object as an HDF5 group in the given parent group"""
        # fixme: use print_date(...) to notify the user
        assert isinstance(parent_group, h5py.File)
        if name:
            group = parent_group.create_group(name)
        else:
            group = parent_group
        group['name'] = self.name if self.name else ''
        group['version'] = self.version
        group['primaryDescriptor'] = self.primary_descriptor
        # if we are adding another group then don't set dict style; just return the populated group
        group = self.software.as_hff(group)
        group = self.transforms.as_hff(group)
        if self.bounding_box.xmax:
            group = self.bounding_box.as_hff(group)
        if self.global_external_references:
            vl_str = h5py.special_dtype(vlen=str)
            h_gext = group.create_dataset(
                "globalExternalReferences",
                (self.num_global_external_references,),
                dtype=[
                    ('type', vl_str),
                    ('otherType', vl_str),
                    ('value', vl_str),
                    ('label', vl_str),
                    ('description', vl_str),
                ]
            )
            i = 0
            for g_ext_ref in self.global_external_references:
                h_gext[i] = (
                    g_ext_ref.type, g_ext_ref.other_type, g_ext_ref.value, g_ext_ref.label, g_ext_ref.description)
                i += 1
        group = self.segments.as_hff(group)
        group = self.lattices.as_hff(group)
        group['details'] = self.details if self.details else ''
        return parent_group

    @classmethod
    def from_hff(cls, hff_data):
        """Create an :py:class:`sfftkrw.schema.SFFSegmentation` object from HDF5 formatted data

        :param hff_data: an HDF5 File object
        :type hff_data: ``h5py.File``
        :return sff_seg: an EMDB-SFF segmentation
        :rtype sff_seg: :py:class:`sfftkrw.schema.SFFSegmentation`
        """
        assert isinstance(hff_data, h5py.File)
        obj = cls()
        try:
            obj.name = _decode(hff_data['name'][()], 'utf-8')
        except KeyError:
            print_date('Segmentation name not found. Please check that {} is a valid EMDB-SFF file'.format(
                hff_data.filename
            ))
            sys.exit(os.EX_DATAERR)
        obj.version = _decode(hff_data['version'][()], 'utf-8')
        obj.software = SFFSoftware.from_hff(hff_data['software'])
        obj.transforms = SFFTransformList.from_hff(hff_data['transforms'])
        obj.primary_descriptor = _decode(hff_data['primaryDescriptor'][()], 'utf-8')
        if 'boundingBox' in hff_data:
            obj.bounding_box = SFFBoundingBox.from_hff(hff_data['boundingBox'])
        if "globalExternalReferences" in hff_data:
            obj.global_external_references = SFFGlobalExternalReferences()
            for gref in hff_data['globalExternalReferences']:
                g = SFFExternalReference()
                g.type, g.other_type, g.value, g.label, g.description = list(map(lambda g: _decode(g, 'utf-8'), gref))
                obj.global_external_references.add_external_reference(g)
        obj.segments = SFFSegmentList.from_hff(hff_data['segments'])
        obj.lattices = SFFLatticeList.from_hff(hff_data['lattices'])
        obj.details = hff_data['details'][()]
        return obj

    def as_json(self, f, sort_keys=True, indent_width=2):
        """Render an EMDB-SFF to JSON

        :param file f: open file handle
        :param bool annotation_only: only extract annotation information and do not render geometric data
        :param bool sort_keys: whether (default) or not to sort keys in the dictionaries
        :param int indent_width: indent width (default: 2)
        """
        """
        :TODO: also extract geometrical data
        """
        sff_data = _dict()
        # can be simplified
        sff_data['name'] = self.name
        sff_data['version'] = self.version
        sff_data['software'] = {
            'name': self.software.name,
            'version': self.software.version,
            'processingDetails': self.software.processing_details if self.software.processing_details is not None else None,
        }
        sff_data['primaryDescriptor'] = self.primary_descriptor
        if self.details is not None:
            sff_data['details'] = _decode(self.details, 'utf-8')
        else:
            sff_data['details'] = None
        sff_data['transforms'] = list()
        bounding_box = {
            'xmin': self.bounding_box.xmin,
            'xmax': self.bounding_box.xmax,
            'ymin': self.bounding_box.ymin,
            'ymax': self.bounding_box.ymax,
            'zmin': self.bounding_box.zmin,
            'zmax': self.bounding_box.zmax,
        }
        sff_data['boundingBox'] = bounding_box
        global_external_references = list()
        for gextref in self.global_external_references:
            global_external_references.append({
                'type': gextref.type,
                'otherType': gextref.other_type,
                'value': gextref.value,
                'label': gextref.label,
                'description': gextref.description
            })
        sff_data['globalExternalReferences'] = global_external_references
        sff_data['segments'] = list()
        for segment in self.segments:
            seg_data = _dict()
            seg_data['id'] = int(segment.id)
            seg_data['parentID'] = int(segment.parentID)
            bio_ann = _dict()
            bio_ann[
                'name'] = segment.biological_annotation.name if segment.biological_annotation.name is not None else None
            bio_ann['description'] = str(
                segment.biological_annotation.description) if segment.biological_annotation.description is not None else None
            bio_ann[
                'numberOfInstances'] = segment.biological_annotation.number_of_instances if segment.biological_annotation.number_of_instances is not None else None

            bio_ann['externalReferences'] = list()
            if segment.biological_annotation.external_references:
                for extref in segment.biological_annotation.external_references:
                    bio_ann['externalReferences'].append(
                        {
                            'type': extref.type,
                            'otherType': extref.other_type,
                            'value': extref.value,
                            'label': extref.label,
                            'description': extref.description,
                        }
                    )
            seg_data['biologicalAnnotation'] = bio_ann
            if segment.complexes_and_macromolecules:
                complexes = list()
                for _complex in segment.complexes_and_macromolecules.complexes:
                    complexes.append(_complex)
                macromolecules = list()
                for macromolecule in segment.complexes_and_macromolecules.macromolecules:
                    macromolecules.append(macromolecule)
                seg_data['complexesAndMacromolecules'] = {
                    'complexes': complexes,
                    'macromolecules': macromolecules,
                }
            seg_data['colour'] = tuple(map(float, segment.colour.value))
            if segment.meshes:
                seg_data['meshList'] = len(segment.meshes)
            if segment.shapes:
                seg_data['shapePrimitiveList'] = len(segment.shapes)
            sff_data['segments'].append(seg_data)
        # write to f
        with f:
            import json
            # print(sff_data, file=sys.stderr)
            json.dump(sff_data, f, sort_keys=sort_keys, indent=indent_width)

    @classmethod
    def from_json(cls, json_file):
        """Create an :py:class:`sfftkrw.schema.SFFSegmentation` object from JSON formatted data

        :param str json_file: name of a JSON-formatted file
        :return sff_seg: an EMDB-SFF segmentation
        :rtype sff_seg: :py:class:`sfftkrw.schema.SFFSegmentation`
        """
        with open(json_file) as j:
            import json
            J = json.load(j)
        sff_seg = cls()
        # header
        sff_seg.name = J['name']
        sff_seg.version = J['version']
        sff_seg.software = SFFSoftware(
            name=J['software']['name'],
            version=J['software']['version'],
            processingDetails=J['software']['processingDetails'],
        )
        sff_seg.primary_descriptor = J['primaryDescriptor']
        if 'boundingBox' in J:
            sff_seg.bounding_box = SFFBoundingBox(
                xmin=J['boundingBox']['xmin'],
                xmax=J['boundingBox']['xmax'],
                ymin=J['boundingBox']['ymin'],
                ymax=J['boundingBox']['ymax'],
                zmin=J['boundingBox']['zmin'],
                zmax=J['boundingBox']['zmax'],
            )
        if 'globalExternalReferences' in J:
            sff_seg.global_external_references = SFFGlobalExternalReferences()
            for gextref in J['globalExternalReferences']:
                try:
                    label = gextref['label']
                except KeyError:
                    label = None
                try:
                    description = gextref['description']
                except KeyError:
                    description = None
                sff_seg.global_external_references.add_external_reference(
                    SFFExternalReference(
                        type=gextref['type'],
                        otherType=gextref['otherType'],
                        value=gextref['value'],
                        label=label,
                        description=description,
                    )
                )
        # segments
        segments = SFFSegmentList()
        for s in J['segments']:
            r, g, b, a = s['colour']
            segment = SFFSegment()
            segment.id = s['id']
            segment.parentID = s['parentID']
            if 'biologicalAnnotation' in s:
                biological_annotation = SFFBiologicalAnnotation()
                biological_annotation.name = s['biologicalAnnotation']['name']
                biological_annotation.description = s['biologicalAnnotation']['description']
                biological_annotation.number_of_instances = s['biologicalAnnotation']['numberOfInstances']
                if 'externalReferences' in s['biologicalAnnotation']:
                    biological_annotation.external_references = SFFExternalReferences()
                    for ext_ref in s['biologicalAnnotation']['externalReferences']:
                        try:
                            label = ext_ref['label']
                        except KeyError:
                            label = None
                        try:
                            description = ext_ref['description']
                        except KeyError:
                            description = None
                        external_reference = SFFExternalReference(
                            type=ext_ref['type'],
                            otherType=ext_ref['otherType'],
                            value=ext_ref['value'],
                            label=label,
                            description=description,
                        )
                        biological_annotation.external_references.add_external_reference(external_reference)
                segment.biological_annotation = biological_annotation
            if 'complexesAndMacromolecules' in s:
                complexes_and_macromolecules = SFFComplexesAndMacromolecules()
                if 'complexes' in s['complexesAndMacromolecules']:
                    complexes = SFFComplexes()
                    complexes.set_complexes(s['complexesAndMacromolecules']['complexes'])
                    complexes_and_macromolecules.complexes = complexes
                if 'macromolecules' in s['complexesAndMacromolecules']:
                    macromolecules = SFFMacromolecules()
                    macromolecules.set_macromolecules(s['complexesAndMacromolecules']['macromolecules'])
                    complexes_and_macromolecules.macromolecules = macromolecules
                segment.complexes_and_macromolecules = complexes_and_macromolecules
            segment.colour = SFFRGBA(
                red=r,
                green=g,
                blue=b,
                alpha=a,
            )
            # in order for sff notes to work with JSON there should be an empty geom
            if 'meshList' in s:
                segment.meshes = SFFMeshList()
                for _ in _xrange(s['meshList']):
                    segment.meshes.add_mesh(SFFMesh())
            if 'threeDVolume' in s:
                # fixme: invalid model
                segment.volume = SFFThreeDVolume()
            if 'shapePrimitiveList' in s:
                segment.shapes = SFFShapePrimitiveList()
                for _ in _xrange(s['shapePrimitiveList']):
                    segment.shapes.add_shape(SFFEllipsoid())
            segments.add_segment(segment)
        sff_seg.segments = segments
        # details
        sff_seg.details = J['details']
        return sff_seg

    # todo: the following methods should be moved to sfftk from sfftk-rw
    def merge_annotation(self, other_seg):
        """Merge the annotation from another sff_seg to this one

        :param other_seg: segmentation to get annotations from
        :type other_seg: :py:class:`sfftk.schema.SFFSegmentation`
        """
        try:
            assert isinstance(other_seg, SFFSegmentation)
        except AssertionError:
            print_date("Invalid type for other_seg: {}".format(type(other_seg)))
            sys.exit(os.EX_DATAERR)
        # global data
        self.name = other_seg.name
        self.software = other_seg.software
        self.global_external_references = other_seg.global_external_references
        self.details = other_seg.details
        # loop through segments
        for segment in self.segments:
            other_segment = other_seg.segments.get_by_id(segment.id)
            segment.biological_annotation = other_segment.biological_annotation
            segment.complexes_and_macromolecules = other_segment.complexes_and_macromolecules

    def copy_annotation(self, from_id, to_id):
        """Copy annotation across segments

        :param int/list from_id: segment ID to get notes from; use -1 for for global notes
        :param int/list to_id: segment ID to copy notes to; use -1 for global notes
        """
        if from_id == -1:
            _from = self.global_external_references
        else:
            _from = self.segments.get_by_id(from_id).biological_annotation.external_references
        if to_id == -1:
            to = self.global_external_references
        else:
            to = self.segments.get_by_id(to_id).biological_annotation.external_references
        # the id for global notes
        for extref in _from:
            to.add_external_reference(extref)

    def clear_annotation(self, from_id):
        """Clear all annotations from the segment with ID specified

        :param from_id: segment ID
        :return:
        """
        if from_id == -1:
            self.global_external_references = SFFGlobalExternalReferences()
        else:
            segment = self.segments.get_by_id(from_id)
            segment.biological_annotation.external_references = SFFExternalReferences()
